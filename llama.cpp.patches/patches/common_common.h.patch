diff --git a/common/common.h b/common/common.h
index 54b7849b..343d9279 100644
--- a/llama.cpp/common/common.h
+++ b/llama.cpp/common/common.h
@@ -277,6 +277,11 @@ struct common_params {
     int32_t n_predict             =    -1; // new tokens to predict
     int32_t n_ctx                 =  4096; // context size
     int32_t n_batch               =  2048; // logical batch size for prompt processing (must be >=32 to use BLAS)
+    // mmojo-server START
+    // This could be automated by searching for "int32_t n_batch " and inserting this block immediately below. -Brad 2025-11-05
+    int32_t n_batch_sleep_ms          =     0; // delay in milliseconds after processing each batch.
+    std::string default_ui_endpoint   =    ""; // endpoint for chat UI
+    // mmojo-server END
     int32_t n_ubatch              =   512; // physical batch size for prompt processing (must be >=32 to use BLAS)
     int32_t n_keep                =     0; // number of tokens to keep from initial prompt
     int32_t n_chunks              =    -1; // max number of chunks to process (-1 = unlimited)
